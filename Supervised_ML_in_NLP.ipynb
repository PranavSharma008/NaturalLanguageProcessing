{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Supervised ML in NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDlccpvZ1FN6"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using any of the three classifiers described in this chapter, and any features you can think of, build the best name gender classifier you can. Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set. How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect?"
      ],
      "metadata": {
        "id": "DVv-ARef1JrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import names"
      ],
      "metadata": {
        "id": "vK08kKJE1WIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('names')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGU0QTGL1g1G",
        "outputId": "6f05b8bd-ad62-45f1-e688-91d05ac57500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Package names is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 classifiers are Naives, Decision Tree and Maximum Entropy Classifiers."
      ],
      "metadata": {
        "id": "PSA5kXfg1j0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gender_features(name):\n",
        "  stng = name\n",
        "  return {'last two letters':stng[-2:]}\n"
      ],
      "metadata": {
        "id": "Nmh8Xq2S7Pzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gender_features('names')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZf92D8Z3EUM",
        "outputId": "ff2c7d08-5611-4a51-b3ac-8eddec54e04e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'last two letters': 'es'}"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labelled_names = [(name,'male') for name in names.words('male.txt')] + [(name,'female') for name in names.words('female.txt')]\n",
        "import random\n",
        "random.shuffle(labelled_names)"
      ],
      "metadata": {
        "id": "ECJfnCSZ3yOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(labelled_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWP0RQMF4azN",
        "outputId": "14899373-3c91-4031-f00f-c88409c5f12a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7944"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features2 = [(gender_features(g) , gender) for (g,gender) in labelled_names]\n",
        "test_set, dev_test, train_set = features2[:500] , features2[500:1000] , features2[1000:]"
      ],
      "metadata": {
        "id": "TuGYkab23HTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier1 = nltk.NaiveBayesClassifier.train(train_set)"
      ],
      "metadata": {
        "id": "GveFQFHW44he"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier2 = nltk.DecisionTreeClassifier.train(train_set)"
      ],
      "metadata": {
        "id": "h5VPfUMd3KmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier3=  nltk.MaxentClassifier.train(train_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_IHliFxB-0P",
        "outputId": "6ec6b90c-f7bb-4425-c259-6eb10a346a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ==> Training (100 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -0.69315        0.372\n",
            "             2          -0.34613        0.802\n",
            "             3          -0.33612        0.802\n",
            "             4          -0.33017        0.802\n",
            "             5          -0.32621        0.802\n",
            "             6          -0.32340        0.802\n",
            "             7          -0.32129        0.802\n",
            "             8          -0.31966        0.802\n",
            "             9          -0.31836        0.802\n",
            "            10          -0.31729        0.802\n",
            "            11          -0.31640        0.802\n",
            "            12          -0.31565        0.802\n",
            "            13          -0.31501        0.802\n",
            "            14          -0.31445        0.802\n",
            "            15          -0.31396        0.802\n",
            "            16          -0.31353        0.802\n",
            "            17          -0.31315        0.802\n",
            "            18          -0.31281        0.802\n",
            "            19          -0.31250        0.802\n",
            "            20          -0.31222        0.802\n",
            "            21          -0.31197        0.802\n",
            "            22          -0.31174        0.802\n",
            "            23          -0.31153        0.802\n",
            "            24          -0.31134        0.802\n",
            "            25          -0.31116        0.802\n",
            "            26          -0.31099        0.802\n",
            "            27          -0.31084        0.802\n",
            "            28          -0.31069        0.802\n",
            "            29          -0.31056        0.802\n",
            "            30          -0.31043        0.802\n",
            "            31          -0.31032        0.802\n",
            "            32          -0.31021        0.802\n",
            "            33          -0.31010        0.802\n",
            "            34          -0.31000        0.802\n",
            "            35          -0.30991        0.802\n",
            "            36          -0.30982        0.802\n",
            "            37          -0.30974        0.802\n",
            "            38          -0.30966        0.802\n",
            "            39          -0.30959        0.802\n",
            "            40          -0.30952        0.802\n",
            "            41          -0.30945        0.802\n",
            "            42          -0.30939        0.802\n",
            "            43          -0.30932        0.802\n",
            "            44          -0.30926        0.802\n",
            "            45          -0.30921        0.802\n",
            "            46          -0.30915        0.802\n",
            "            47          -0.30910        0.802\n",
            "            48          -0.30905        0.802\n",
            "            49          -0.30901        0.802\n",
            "            50          -0.30896        0.802\n",
            "            51          -0.30892        0.802\n",
            "            52          -0.30887        0.802\n",
            "            53          -0.30883        0.802\n",
            "            54          -0.30879        0.802\n",
            "            55          -0.30876        0.802\n",
            "            56          -0.30872        0.802\n",
            "            57          -0.30869        0.802\n",
            "            58          -0.30865        0.802\n",
            "            59          -0.30862        0.802\n",
            "            60          -0.30859        0.802\n",
            "            61          -0.30856        0.802\n",
            "            62          -0.30853        0.802\n",
            "            63          -0.30850        0.802\n",
            "            64          -0.30847        0.802\n",
            "            65          -0.30844        0.802\n",
            "            66          -0.30842        0.802\n",
            "            67          -0.30839        0.802\n",
            "            68          -0.30837        0.802\n",
            "            69          -0.30834        0.802\n",
            "            70          -0.30832        0.802\n",
            "            71          -0.30830        0.802\n",
            "            72          -0.30827        0.802\n",
            "            73          -0.30825        0.802\n",
            "            74          -0.30823        0.802\n",
            "            75          -0.30821        0.802\n",
            "            76          -0.30819        0.802\n",
            "            77          -0.30817        0.802\n",
            "            78          -0.30815        0.802\n",
            "            79          -0.30813        0.802\n",
            "            80          -0.30812        0.802\n",
            "            81          -0.30810        0.802\n",
            "            82          -0.30808        0.802\n",
            "            83          -0.30807        0.802\n",
            "            84          -0.30805        0.802\n",
            "            85          -0.30803        0.802\n",
            "            86          -0.30802        0.802\n",
            "            87          -0.30800        0.802\n",
            "            88          -0.30799        0.802\n",
            "            89          -0.30797        0.802\n",
            "            90          -0.30796        0.802\n",
            "            91          -0.30794        0.802\n",
            "            92          -0.30793        0.802\n",
            "            93          -0.30792        0.802\n",
            "            94          -0.30790        0.802\n",
            "            95          -0.30789        0.802\n",
            "            96          -0.30788        0.802\n",
            "            97          -0.30787        0.802\n",
            "            98          -0.30786        0.802\n",
            "            99          -0.30784        0.802\n",
            "         Final          -0.30783        0.802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.classify.accuracy(classifier1,dev_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SICJzsJG7meW",
        "outputId": "e905748f-b4d9-4353-a14e-a303030650fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.786"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.classify.accuracy(classifier3,dev_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwrZqnFUCHCx",
        "outputId": "8e0fffa1-2428-4aef-e1f0-cde3c1639772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.798"
            ]
          },
          "metadata": {},
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.classify.accuracy(classifier2,dev_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3p2wBTC7xNi",
        "outputId": "be427242-c67c-4fcf-88e7-07020c85265e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.786"
            ]
          },
          "metadata": {},
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.classify.accuracy(classifier2,test_set)"
      ],
      "metadata": {
        "id": "H3j1oT-L716O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf622bd4-9b47-43d1-9f62-3dcb6df63b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.804"
            ]
          },
          "metadata": {},
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.classify.accuracy(classifier1,test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCczt2wR6Bqm",
        "outputId": "090f0078-0efb-4c91-a640-c67e1a8a4128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.762"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.classify.accuracy(classifier3,test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCe5YmGDCSnv",
        "outputId": "8a022031-391f-407f-892a-496d43c61058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.812"
            ]
          },
          "metadata": {},
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " The Senseval 2 Corpus contains data intended to train word-sense disambiguation classifiers. It contains data for four words: hard, interest, line, and serve. Choose one of these four words, and load the corresponding data:"
      ],
      "metadata": {
        "id": "-oAmMHC56DiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import senseval\n",
        "nltk.download('senseval')\n",
        "instances_hard = senseval.instances('hard.pos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7gBK6t36t0C",
        "outputId": "31100053-c0cf-4139-97e8-b10717833214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]   Package senseval is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instances_interest = senseval.instances('interest.pos')"
      ],
      "metadata": {
        "id": "kZ4FwVl8Bn37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = int(len(instances_hard) * 0.1)\n",
        "train_set, test_set = instances_hard[420:], instances_hard[:420]"
      ],
      "metadata": {
        "id": "SQazSjPV65F6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_sensual=[]"
      ],
      "metadata": {
        "id": "rzf9tdWqW26E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "k2JBZEgVYMJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(instances_hard)-1):\n",
        "  for k in range(1,len(instances_hard[i].context)-2):\n",
        "    if (instances_hard[i].context[k][0]=='hard'):\n",
        "      features_sensual.append([{'POS word before hard': instances_hard[i].context[k-1][1] ,\n",
        "                                'POS of word hard' :instances_hard[i].context[k][1],\n",
        "                                'POS of word after hard': instances_hard[i].context[k+1][1]}\n",
        "                               ,instances_hard[i].senses[0]])\n"
      ],
      "metadata": {
        "id": "fznKb7_ZYQon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sense_features(instances_hardy):\n",
        "  features_sensual=[]\n",
        "  for i in range(0,len(instances_hardy)-1):\n",
        "    for k in range(1,len(instances_hardy[i].context)-2):\n",
        "      if (instances_hardy[i].context[k][0]=='hard'):\n",
        "        features_sensual.append([{'POS word before hard': instances_hardy[i].context[k-1][1] \n",
        "                                ,'POS of word hard' :instances_hardy[i].context[k][1]\n",
        "                                ,'POS of word after hard': instances_hardy[i].context[k+1][1]\n",
        "                                }\n",
        "                               ,instances_hardy[i].senses[0]])\n",
        "  return features_sensual\n",
        "    "
      ],
      "metadata": {
        "id": "6xDwlWyHVDy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_hard  = [(before, sense ) for (before,sense )in sense_features(instances_hard)]\n",
        "import random"
      ],
      "metadata": {
        "id": "u8OF-W7HZChl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(instances_hard)\n",
        "len(features_hard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTB6T2tzdIB3",
        "outputId": "427d7a7d-756e-47ca-f405-6423c3b8766d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3652"
            ]
          },
          "metadata": {},
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(features_hard)\n",
        "test_set, train_set = features_hard[:1000] , features_hard[1000:]"
      ],
      "metadata": {
        "id": "iDHcwiD6abap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import NaiveBayesClassifier "
      ],
      "metadata": {
        "id": "u-3qoZI_tlqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_hard1 = nltk.NaiveBayesClassifier.train(train_set)\n",
        "classifier_hard2 = nltk.DecisionTreeClassifier.train(train_set)\n",
        "classifier_hard3 = nltk.MaxentClassifier.train(train_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap7oo-X97L-A",
        "outputId": "4b8b5ef0-37fe-415a-8404-9bceab927775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ==> Training (100 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -1.09861        0.101\n",
            "             2          -0.32987        0.772\n",
            "             3          -0.31554        0.798\n",
            "             4          -0.30587        0.817\n",
            "             5          -0.29952        0.823\n",
            "             6          -0.29512        0.823\n",
            "             7          -0.29193        0.821\n",
            "             8          -0.28953        0.821\n",
            "             9          -0.28768        0.821\n",
            "            10          -0.28622        0.823\n",
            "            11          -0.28505        0.823\n",
            "            12          -0.28408        0.823\n",
            "            13          -0.28329        0.823\n",
            "            14          -0.28262        0.823\n",
            "            15          -0.28205        0.823\n",
            "            16          -0.28156        0.823\n",
            "            17          -0.28114        0.823\n",
            "            18          -0.28077        0.823\n",
            "            19          -0.28044        0.823\n",
            "            20          -0.28015        0.823\n",
            "            21          -0.27989        0.823\n",
            "            22          -0.27966        0.822\n",
            "            23          -0.27945        0.822\n",
            "            24          -0.27926        0.822\n",
            "            25          -0.27908        0.822\n",
            "            26          -0.27892        0.822\n",
            "            27          -0.27878        0.822\n",
            "            28          -0.27864        0.822\n",
            "            29          -0.27852        0.822\n",
            "            30          -0.27840        0.822\n",
            "            31          -0.27829        0.822\n",
            "            32          -0.27819        0.823\n",
            "            33          -0.27809        0.823\n",
            "            34          -0.27801        0.823\n",
            "            35          -0.27792        0.823\n",
            "            36          -0.27784        0.823\n",
            "            37          -0.27777        0.823\n",
            "            38          -0.27770        0.823\n",
            "            39          -0.27763        0.823\n",
            "            40          -0.27757        0.823\n",
            "            41          -0.27751        0.823\n",
            "            42          -0.27745        0.823\n",
            "            43          -0.27739        0.823\n",
            "            44          -0.27734        0.823\n",
            "            45          -0.27729        0.823\n",
            "            46          -0.27724        0.823\n",
            "            47          -0.27720        0.823\n",
            "            48          -0.27715        0.823\n",
            "            49          -0.27711        0.823\n",
            "            50          -0.27707        0.823\n",
            "            51          -0.27703        0.823\n",
            "            52          -0.27699        0.823\n",
            "            53          -0.27696        0.823\n",
            "            54          -0.27692        0.823\n",
            "            55          -0.27689        0.823\n",
            "            56          -0.27686        0.823\n",
            "            57          -0.27682        0.823\n",
            "            58          -0.27679        0.823\n",
            "            59          -0.27676        0.823\n",
            "            60          -0.27674        0.823\n",
            "            61          -0.27671        0.823\n",
            "            62          -0.27668        0.823\n",
            "            63          -0.27665        0.823\n",
            "            64          -0.27663        0.823\n",
            "            65          -0.27660        0.823\n",
            "            66          -0.27658        0.823\n",
            "            67          -0.27656        0.823\n",
            "            68          -0.27653        0.823\n",
            "            69          -0.27651        0.823\n",
            "            70          -0.27649        0.823\n",
            "            71          -0.27647        0.823\n",
            "            72          -0.27645        0.823\n",
            "            73          -0.27643        0.823\n",
            "            74          -0.27641        0.823\n",
            "            75          -0.27639        0.823\n",
            "            76          -0.27637        0.822\n",
            "            77          -0.27635        0.822\n",
            "            78          -0.27633        0.822\n",
            "            79          -0.27632        0.822\n",
            "            80          -0.27630        0.822\n",
            "            81          -0.27628        0.822\n",
            "            82          -0.27627        0.822\n",
            "            83          -0.27625        0.822\n",
            "            84          -0.27624        0.822\n",
            "            85          -0.27622        0.822\n",
            "            86          -0.27621        0.822\n",
            "            87          -0.27619        0.822\n",
            "            88          -0.27618        0.822\n",
            "            89          -0.27616        0.822\n",
            "            90          -0.27615        0.822\n",
            "            91          -0.27613        0.822\n",
            "            92          -0.27612        0.822\n",
            "            93          -0.27611        0.822\n",
            "            94          -0.27610        0.822\n",
            "            95          -0.27608        0.822\n",
            "            96          -0.27607        0.822\n",
            "            97          -0.27606        0.822\n",
            "            98          -0.27605        0.822\n",
            "            99          -0.27603        0.822\n",
            "         Final          -0.27602        0.822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.classify.accuracy(classifier_hard3,test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0oirEW9A_MA",
        "outputId": "4caf013d-07bf-4d66-ec9f-0e5a75466c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.833"
            ]
          },
          "metadata": {},
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.classify.accuracy(classifier_hard1,test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpiSmExY7Tio",
        "outputId": "aff92e46-7b84-40fa-eba8-f10f7c49c22c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.781"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.classify.accuracy(classifier_hard2,test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw_03FxabFGY",
        "outputId": "8042154b-4857-48e4-a5a0-d35766fe26b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.837"
            ]
          },
          "metadata": {},
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Trees classifier is found optimum as compared to NaiveBayes in this condition"
      ],
      "metadata": {
        "id": "F19mP-9lt31a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import movie_reviews"
      ],
      "metadata": {
        "id": "zihwss9JusBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the movie review document classifier discussed in this chapter, generate a list of the 30 features that the classifier finds to be most informative. Can you explain why these particular features are informative? Do you find any of them surprising?"
      ],
      "metadata": {
        "id": "uLg4DAew-9Bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import movie_reviews\n",
        "nltk.download('movie_reviews')\n",
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "              for fileid in movie_reviews.fileids(category)]\n",
        "random.shuffle(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La8OiWw7wCGM",
        "outputId": "13fc36c7-8f4f-4f7a-fac1-c76de0102e8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
        "word_features = list(all_words)[:2000] \n",
        "\n",
        "def document_features(document): \n",
        "    document_words = set(document) \n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features['contains({})'.format(word)] = (word in document_words)\n",
        "    return features"
      ],
      "metadata": {
        "id": "JJ504RfU9bxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
        "train_set, test_set = featuresets[100:], featuresets[:100]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)"
      ],
      "metadata": {
        "id": "mgbsMHEP9tre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.show_most_informative_features(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7RuXr66AYv2",
        "outputId": "c48202e6-b50f-45fd-eb09-5c6c99b76e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            " contains(unimaginative) = True              neg : pos    =      7.7 : 1.0\n",
            "    contains(schumacher) = True              neg : pos    =      7.4 : 1.0\n",
            "        contains(shoddy) = True              neg : pos    =      7.0 : 1.0\n",
            "        contains(suvari) = True              neg : pos    =      7.0 : 1.0\n",
            "          contains(mena) = True              neg : pos    =      7.0 : 1.0\n",
            "        contains(turkey) = True              neg : pos    =      6.8 : 1.0\n",
            "     contains(atrocious) = True              neg : pos    =      6.6 : 1.0\n",
            "          contains(rope) = True              neg : pos    =      6.3 : 1.0\n",
            "       contains(singers) = True              pos : neg    =      6.3 : 1.0\n",
            "        contains(justin) = True              neg : pos    =      5.8 : 1.0\n",
            "           contains(ugh) = True              neg : pos    =      5.8 : 1.0\n",
            "  contains(surveillance) = True              neg : pos    =      5.7 : 1.0\n",
            "       contains(bronson) = True              neg : pos    =      5.7 : 1.0\n",
            "        contains(canyon) = True              neg : pos    =      5.7 : 1.0\n",
            "       contains(unravel) = True              pos : neg    =      5.7 : 1.0\n",
            "         contains(awful) = True              neg : pos    =      5.3 : 1.0\n",
            "        contains(wasted) = True              neg : pos    =      5.2 : 1.0\n",
            "     contains(underwood) = True              neg : pos    =      5.0 : 1.0\n",
            "          contains(diva) = True              neg : pos    =      5.0 : 1.0\n",
            "          contains(oops) = True              neg : pos    =      5.0 : 1.0\n",
            "        contains(welles) = True              neg : pos    =      5.0 : 1.0\n",
            "        contains(poorly) = True              neg : pos    =      4.9 : 1.0\n",
            "         contains(waste) = True              neg : pos    =      4.9 : 1.0\n",
            "    contains(ridiculous) = True              neg : pos    =      4.8 : 1.0\n",
            "        contains(inject) = True              neg : pos    =      4.7 : 1.0\n",
            "         contains(kudos) = True              pos : neg    =      4.7 : 1.0\n",
            "    contains(uninspired) = True              neg : pos    =      4.7 : 1.0\n",
            "         contains(groan) = True              neg : pos    =      4.6 : 1.0\n",
            "      contains(explores) = True              pos : neg    =      4.5 : 1.0\n",
            "           contains(h20) = True              neg : pos    =      4.3 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select one of the classification tasks described in this chapter, such as name gender detection, document classification, part-of-speech tagging, or dialog act classification. Using the same training and test data, and the same feature extractor, build three classifiers for the task: a decision tree, a naive Bayes classifier, and a Maximum Entropy classifier. Compare the performance of the three classifiers on your selected task. How do you think that your results might be different if you used a different feature extractor?"
      ],
      "metadata": {
        "id": "DLF6eTnLAe2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Max entropy classifier is the one which gave maximum accuracy."
      ],
      "metadata": {
        "id": "79BaoXm0lbkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uW7YFiMgl4V0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}